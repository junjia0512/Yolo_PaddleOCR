import torch
import cv2
from paddleocr import PaddleOCR
from yolov5.models.experimental import attempt_load
from yolov5.utils.general import non_max_suppression, scale_coords
import os
import glob
import time
import re

def extract_info_from_texts(texts):
    t_start = time.time()
    joined_text = " ".join(texts)
    print("\n=== æå–ç»“æœ ===")

    # ğŸ“® é‚®æ”¿ç¼–ç ï¼ˆ6ä½çº¯æ•°å­—ï¼‰
    zip_codes = re.findall(r"\b\d{6}\b", joined_text)
    if zip_codes:
        print(f"ğŸ“® é‚®æ”¿ç¼–ç : {zip_codes[0]}")
    else:
        print("ğŸ“® æœªæ£€æµ‹åˆ°é‚®æ”¿ç¼–ç ")

    # ğŸ“¦ é‚®ä»¶æ¡ç ï¼ˆ10-15ä½æ•°å­—æˆ–å¤§å†™å­—æ¯æ··åˆï¼‰
    barcodes = re.findall(r"\b[A-Z0-9]{10,15}\b", joined_text)
    if barcodes:
        print(f"ğŸ“¦ é‚®ä»¶æ¡ç : {barcodes[0]}")
    else:
        print("ğŸ“¦ æœªæ£€æµ‹åˆ°é‚®ä»¶æ¡ç ")

    # ğŸ  åœ°å€ï¼ˆåŒ…å«â€œè·¯â€â€œè¡—â€â€œå¼„â€â€œå··â€â€œå·â€â€œå®¤â€ç­‰ï¼‰
    address_lines = [line for line in texts if any(k in line for k in ['è·¯', 'è¡—', 'å¼„', 'å··', 'å·', 'å®¤']) and len(line) > 6]
    if address_lines:
        print(f"ğŸ  æ”¶ä»¶äººåœ°å€: {' '.join(address_lines)}")
    else:
        print("ğŸ  æœªæ£€æµ‹åˆ°æ”¶ä»¶äººåœ°å€")

    # ğŸ‘¤ æ”¶ä»¶äººæå–ç­–ç•¥
    receiver_lines = []

    # 1. æŸ¥æ‰¾å«â€œæ”¶â€â€œå…ˆç”Ÿâ€â€œå¥³å£«â€â€œå°å§â€
    for line in texts:
        if 'æ”¶' in line or 'å…ˆç”Ÿ' in line or 'å¥³å£«' in line or 'å°å§' in line:
            receiver_lines.append(line)
            break

    # 2. æŸ¥æ‰¾â€œäº²å¯â€æˆ–â€œæ•¬å¯â€å‰ä¸€è¡Œ
    if not receiver_lines:
        for i, line in enumerate(texts):
            if ('äº²å¯' in line or 'æ•¬å¯' in line) and i > 0:
                prev_line = texts[i - 1]
                if re.match(r'^[\u4e00-\u9fa5]{2,4}$', prev_line):
                    receiver_lines.append(prev_line)
                    break

    if receiver_lines:
        print(f"ğŸ‘¤ æ”¶ä»¶äºº: {receiver_lines[0]}")
    else:
        print("ğŸ‘¤ æœªæ£€æµ‹åˆ°æ”¶ä»¶äºº")

    print("====================")
    print(f"ğŸ“Š ä¿¡æ¯æå–è€—æ—¶: {time.time() - t_start:.3f} ç§’\n")


# ========================
#        ä¸»ç¨‹åºéƒ¨åˆ†
# ========================

program_start = time.time()


# 1. åŠ è½½YOLOv5æ¨¡å‹
t_yolo_start = time.time()
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = attempt_load('weights/best.pt', map_location=device)
model.eval()
t_yolo_end = time.time()
print(f"âœ… YOLOæ¨¡å‹åŠ è½½å®Œæˆï¼Œç”¨æ—¶: {t_yolo_end - t_yolo_start:.3f} ç§’")

# 2. åŠ è½½å›¾ç‰‡
image_dir = 'train'
image_paths = glob.glob(os.path.join(image_dir, '*.*'))

# 3. åŠ è½½OCRæ¨¡å‹
t_ocr_start = time.time()
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False
)
t_ocr_end = time.time()
print(f"âœ… OCRæ¨¡å‹åŠ è½½å®Œæˆï¼Œç”¨æ—¶: {t_ocr_end - t_ocr_start:.3f} ç§’")

# 4. å¤„ç†æ¯å¼ å›¾ç‰‡
total_image_time = 0

for img_path in image_paths:
    print(f"\nğŸ“· æ­£åœ¨å¤„ç†å›¾ç‰‡: {img_path}")
    total_start = time.time()

    # è¯»å–å›¾ç‰‡
    im0 = cv2.imread(img_path)
    assert im0 is not None, f'Image Not Found {img_path}'
    img = cv2.resize(im0, (640, 640))
    img = img[:, :, ::-1].transpose(2, 0, 1).copy()
    img = torch.from_numpy(img).float() / 255.0
    img = img.unsqueeze(0).to(device)

    # é˜¶æ®µ1ï¼šYOLOæ£€æµ‹
    t1 = time.time()
    with torch.no_grad():
        pred = model(img)[0]
        pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)
    print(f"ğŸ” YOLOæ£€æµ‹è€—æ—¶: {time.time() - t1:.3f} ç§’")

    # é˜¶æ®µ2ï¼šè£å‰ª + OCRè¯†åˆ«
    for det in pred:
        if det is not None and len(det):
            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()
            for *xyxy, conf, cls in det:
                x1, y1, x2, y2 = map(int, xyxy)
                crop_img = im0[y1:y2, x1:x2]

                os.makedirs('output', exist_ok=True)
                save_path = f"output/crop_{os.path.basename(img_path).split('.')[0]}_{x1}_{y1}_{x2}_{y2}.jpg"
                cv2.imwrite(save_path, crop_img)

                t2 = time.time()
                result = ocr.predict(crop_img)
                ocr_time = time.time() - t2
                print(f"ğŸ§¾ OCRè¯†åˆ«è€—æ—¶: {ocr_time:.3f} ç§’")

                if result and isinstance(result, list) and 'rec_texts' in result[0]:
                    texts = result[0]['rec_texts']
                    for text in texts:
                        print(text)
                    extract_info_from_texts(texts)
                else:
                    print("æœªè¯†åˆ«åˆ°æ–‡å­—")

    per_image_time = time.time() - total_start
    total_image_time += per_image_time
    print(f"ğŸ“Œ å›¾ç‰‡æ€»å¤„ç†è€—æ—¶: {per_image_time:.3f} ç§’")

# 5. ç¨‹åºæ€»è€—æ—¶
program_end = time.time()
print("\nâœ… æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼")
print(f"ğŸ•’ æ€»å›¾ç‰‡æ•°: {len(image_paths)}")
print(f"ğŸ•’ æ€»å›¾ç‰‡å¤„ç†è€—æ—¶: {total_image_time:.3f} ç§’")
print(f"ğŸ•’ ç¨‹åºæ€»è¿è¡Œæ—¶é—´: {program_end - program_start:.3f} ç§’")
